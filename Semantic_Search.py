import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
from typing import List, Dict
import re
import warnings
warnings.filterwarnings('ignore')

class SemanticSearcher:
    """Classe pour effectuer une recherche s√©mantique avec Scikit-learn et TF-IDF"""
    
    def __init__(self):
        """Initialise le searcher avec TF-IDF"""
        print(f"üì¶ Initialisation du moteur de recherche s√©mantique")
        print("   Utilisant TF-IDF + Similarit√© Cosinus\n")
        
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            lowercase=True,
            stop_words='english',
            ngram_range=(1, 2),
            min_df=1,
            max_df=0.9
        )
        
        self.products = []
        self.embeddings = None
        self.df = None
        self.titles = []
        
        print(f"‚úÖ Moteur de recherche initialis√© avec succ√®s\n")
    
    def load_products(self, json_file='produits_marjane.json'):
        """Charge les produits depuis un fichier JSON"""
        print(f"üìÇ Chargement des produits depuis {json_file}...")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                self.products = json.load(f)
            
            self.titles = [p.get('title', '') for p in self.products]
            print(f"‚úÖ {len(self.products)} produits charg√©s\n")
            return True
        except FileNotFoundError:
            print(f"‚ùå Fichier {json_file} non trouv√©\n")
            return False
    
    def preprocess_text(self, text):
        """Pr√©traite le texte"""
        if not isinstance(text, str):
            return ""
        
        # Convertir en minuscules
        text = text.lower()
        # Supprimer les caract√®res sp√©ciaux sauf les espaces
        text = re.sub(r'[^a-z\s]', '', text)
        # Supprimer les espaces multiples
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def generate_embeddings(self):
        """G√©n√®re les embeddings TF-IDF pour tous les produits"""
        if not self.products:
            print("‚ùå Aucun produit charg√©")
            return False
        
        print("‚öôÔ∏è  G√©n√©ration des embeddings TF-IDF...")
        print(f"   Total: {len(self.titles)} produits\n")
        
        # Pr√©traiter les titres
        processed_titles = [self.preprocess_text(title) for title in self.titles]
        
        # G√©n√©rer les embeddings TF-IDF
        self.embeddings = self.vectorizer.fit_transform(processed_titles).toarray()
        
        print(f"‚úÖ Embeddings g√©n√©r√©s avec succ√®s")
        print(f"   Forme: {self.embeddings.shape}")
        print(f"   Vocabulaire: {len(self.vectorizer.get_feature_names_out())} termes\n")
        
        return True
    
    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        Effectue une recherche s√©mantique
        
        Args:
            query: Requ√™te de recherche
            top_k: Nombre de r√©sultats √† retourner
        
        Returns:
            Liste des produits les plus similaires
        """
        if self.embeddings is None:
            print("‚ùå Les embeddings ne sont pas g√©n√©r√©s")
            return []
        
        # Pr√©traiter et vectoriser la requ√™te
        processed_query = self.preprocess_text(query)
        query_embedding = self.vectorizer.transform([processed_query]).toarray()
        
        # Calculer la similarit√© cosinus
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        
        # Obtenir les indices des top-k r√©sultats
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        # Pr√©parer les r√©sultats
        results = []
        for idx in top_indices:
            if similarities[idx] > 0:  # Ignorer les r√©sultats avec similarit√© 0
                product = self.products[idx]
                results.append({
                    'index': int(idx),
                    'titre': product.get('title', ''),
                    'prix': product.get('price', ''),
                    'image': product.get('image', ''),
                    'similarite': float(similarities[idx]),
                    'score_pourcentage': float(similarities[idx] * 100)
                })
        
        return results
    
    def display_results(self, results: List[Dict], query: str):
        """Affiche les r√©sultats de la recherche de mani√®re format√©e"""
        print(f"\n{'='*90}")
        print(f"üîç R√âSULTATS POUR: \"{query}\"")
        print(f"{'='*90}\n")
        
        if not results:
            print("‚ùå Aucun r√©sultat trouv√©\n")
            return
        
        for i, result in enumerate(results, 1):
            bar_length = int(result['score_pourcentage'] / 5)
            bar = '‚ñà' * bar_length + '‚ñë' * (20 - bar_length)
            
            print(f"üè∑Ô∏è  R√©sultat {i}")
            print(f"   Titre: {result['titre']}")
            print(f"   Prix: {result['prix']}")
            print(f"   Similarit√©: [{bar}] {result['score_pourcentage']:.1f}%")
            print()
    
    def interactive_search(self):
        """Mode de recherche interactif"""
        print("\n" + "="*90)
        print("üîé MODE DE RECHERCHE INTERACTIF")
        print("="*90)
        print("Tapez votre requ√™te ou 'quit' pour quitter\n")
        
        while True:
            query = input("üîç Votre recherche: ").strip()
            
            if query.lower() == 'quit':
                print("\nüëã Au revoir!")
                break
            
            if not query:
                print("‚ùå Veuillez entrer une requ√™te valide\n")
                continue
            
            results = self.search(query, top_k=5)
            self.display_results(results, query)
    
    def batch_search(self, queries: List[str], top_k: int = 3) -> Dict:
        """Effectue plusieurs recherches √† la fois"""
        print(f"\n{'='*90}")
        print(f"üîç RECHERCHE PAR BATCH ({len(queries)} requ√™tes)")
        print(f"{'='*90}\n")
        
        batch_results = {}
        
        for query in queries:
            results = self.search(query, top_k=top_k)
            batch_results[query] = results
            self.display_results(results, query)
        
        return batch_results
    
    def search_by_category(self, query: str, category: str, top_k: int = 5) -> List[Dict]:
        """Recherche limit√©e √† une cat√©gorie sp√©cifique"""
        try:
            df = pd.read_csv('produits_marjane_clean.csv')
        except FileNotFoundError:
            print("‚ùå Fichier produits_marjane_clean.csv non trouv√©")
            return []
        
        category_indices = df[df['categorie'] == category].index.tolist()
        
        if not category_indices:
            print(f"‚ùå Aucun produit trouv√© dans la cat√©gorie: {category}")
            return []
        
        processed_query = self.preprocess_text(query)
        query_embedding = self.vectorizer.transform([processed_query]).toarray()
        
        category_embeddings = self.embeddings[category_indices]
        similarities = cosine_similarity(query_embedding, category_embeddings)[0]
        
        top_local_indices = np.argsort(similarities)[::-1][:top_k]
        top_global_indices = [category_indices[i] for i in top_local_indices]
        
        results = []
        for i, global_idx in enumerate(top_global_indices):
            product = self.products[global_idx]
            results.append({
                'index': int(global_idx),
                'titre': product.get('title', ''),
                'prix': product.get('price', ''),
                'image': product.get('image', ''),
                'similarite': float(similarities[top_local_indices[i]]),
                'score_pourcentage': float(similarities[top_local_indices[i]] * 100)
            })
        
        return results
    
    def similar_products(self, product_index: int, top_k: int = 5) -> List[Dict]:
        """Trouve les produits similaires √† un produit donn√©"""
        if product_index >= len(self.products):
            print(f"‚ùå Indice de produit invalide: {product_index}")
            return []
        
        product_embedding = self.embeddings[product_index:product_index+1]
        similarities = cosine_similarity(product_embedding, self.embeddings)[0]
        
        similarities[product_index] = -1
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            product = self.products[idx]
            results.append({
                'index': int(idx),
                'titre': product.get('title', ''),
                'prix': product.get('price', ''),
                'image': product.get('image', ''),
                'similarite': float(similarities[idx]),
                'score_pourcentage': float(similarities[idx] * 100)
            })
        
        return results
    
    def export_results(self, results: Dict, filename: str = 'search_results.json'):
        """Exporte les r√©sultats en JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\n‚úÖ R√©sultats export√©s dans {filename}")

def main():
    """Fonction principale"""
    print("\n" + "="*90)
    print("üöÄ SEMANTIC SEARCH AVEC TF-IDF")
    print("="*90 + "\n")
    
    # Initialiser le searcher
    searcher = SemanticSearcher()
    
    # Charger les produits
    if not searcher.load_products():
        return
    
    # G√©n√©rer les embeddings
    if not searcher.generate_embeddings():
        return
    
    # Exemples de recherches
    print("="*90)
    print("üìã EXEMPLES DE RECHERCHES S√âMANTIQUES")
    print("="*90)
    
    test_queries = [
        "produits de beaut√©",
        "√©lectronique pas cher",
        "chocolat et bonbons",
        "nettoyage de maison",
        "produits bio"
    ]
    
    batch_results = searcher.batch_search(test_queries, top_k=3)
    
    # Sauvegarder les r√©sultats
    searcher.export_results(batch_results, 'search_results.json')
    
    # Recherche interactive
    print("\n" + "="*90)
    print("‚ú® MODE INTERACTIF")
    print("="*90)
    print("\nVoulez-vous essayer le mode interactif? (oui/non)")
    response = input("R√©ponse: ").strip().lower()
    
    if response in ['oui', 'yes', 'o', 'y']:
        searcher.interactive_search()
    else:
        print("\nüëã Merci d'avoir utilis√© le Semantic Search!")
    
    print("\n" + "="*90)
    print("‚úÖ PROGRAMME TERMIN√â")
    print("="*90 + "\n")

if __name__ == "__main__":
    main()
